{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"only_normalised","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"CMYB7Qd9lo6r","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from keras import backend as K\n","\n","num_cores = 4\n","\n","GPU = True\n","CPU = True\n","if GPU:\n","    num_GPU = 1\n","    num_CPU = 1\n","elif CPU:\n","    num_CPU = 1\n","    num_GPU = 0\n","\n","config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\n","                        inter_op_parallelism_threads=num_cores, \n","                        allow_soft_placement=True,\n","                        device_count = {'CPU' : num_CPU,\n","                                        'GPU' : num_GPU}\n","                       )\n","\n","session = tf.Session(config=config)\n","K.set_session(session)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oHMe_6Ohlr4W","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","path = '/content/datasets/en_train.csv'\n","\n","file_en = open(path)\n","\n","df_pandas = pd.read_csv(path,  names = [\"sentence_id\", \"token_id\", \"class\", \"before\", \"after\"], low_memory=False)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YxxSQKVEluK3","colab_type":"code","outputId":"1bb3b095-72c9-4f31-cbd8-1c07535f6a7a","executionInfo":{"status":"ok","timestamp":1554427525566,"user_tz":-330,"elapsed":3190,"user":{"displayName":"Amit kumar Yadav","photoUrl":"https://lh6.googleusercontent.com/-N6yYQFfFDuU/AAAAAAAAAAI/AAAAAAAAIbQ/hSVCtjem3l8/s64/photo.jpg","userId":"00337954032911416954"}},"colab":{"base_uri":"https://localhost:8080/","height":201}},"cell_type":"code","source":["# for i in file_en:\n","#     list_row = i.split(',')\n","#     for i, j in enumerate(list_row):\n","#         list_row[i] = list_row[i].replace(\"\\\"\", '')\n","#     if not (list_row[2] == 'PLAIN' or list_row[2] == 'PUNCT'):\n","#         # print list_row[3], list_row[4]\n","#         out_file.write(' '.join(list(list_row[3])) + '\\t' + list_row[4])\n","#\n","# out_file.close()\n","# print(df_pandas.keys[:5])\n","\n","import csv\n","\n","out_file = open('/content/datasets/en_train_normalised.csv', 'w')\n","\n","print(len(df_pandas))\n","\n","k=0\n","for sent_id, class_type, before, after in zip(df_pandas['sentence_id'], df_pandas['class'], df_pandas['before'], df_pandas['after']):\n","    if not (class_type == 'PLAIN' or class_type == 'PUNCT'):\n","        # print class_type, before, after\n","        # print ' '.join(list(before)), '\\t', after\n","        if k < 10:\n","            print(sent_id, before, after)\n","        words  = [before, after]\n","        writer = csv.writer(out_file)\n","        writer.writerow(words)\n","        #out_file.write(' '.join(list(str(before))) + ',' + after + '\\n')\n","        k = k + 1\n","\n","out_file.close()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["310919\n","sentence_id before after\n","1 2006 two thousand six\n","1 IUCN i u c n\n","3 2007 two thousand seven\n","5 2008 two thousand eight\n","6 91 ninety one\n","8 04-Mar-14 the fourth of march twenty fourteen\n","9 BC b c\n","9 3 three\n","10 35 thirty five\n"],"name":"stdout"}]}]}